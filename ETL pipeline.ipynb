{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-d31a6683f073>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-d31a6683f073>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    def __init__(self, host, database, user):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector \n",
    "from mysql.connector import Error\n",
    "import os\n",
    "import re\n",
    "import pandas as pd \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "\n",
    "class TweetObject():\n",
    "\n",
    "\n",
    "def __init__(self, host, database, user):\n",
    "self.password = os.environ['PASSWORD']\n",
    "self.host = host\n",
    "Self.database = database\n",
    "self.user = user\n",
    "\n",
    "\n",
    "\n",
    "def MySQLConnect(self,query):\n",
    "\"\"\"\n",
    "\t\tConnects to database and extracts\n",
    "\t\traw tweets and any other columns we\n",
    "\t\tneed\n",
    "\t\tParameters:\n",
    "\t\t----------------\n",
    "\t\targ1: string: SQL query\n",
    "\t\tReturns: Pandas Dataframe\n",
    "\t\t----------------\n",
    "\t\t\"\"\"\n",
    "\n",
    "try:\n",
    "con = mysql.connector.connect(host = self.host, database = self.database, \\\n",
    "user = self.user, password = self.password, charset = 'utf8')\n",
    "\n",
    "if con.is_connected():\n",
    "print(\"Successfully connected to database\")\n",
    "cursor = con.cursor()\n",
    "query = query\n",
    "cursor.execute(query)\n",
    "\n",
    "data = cursor.fetchall()\n",
    "# store in dataframe\n",
    "df = pd.DataFrame(data,columns = ['date', 'tweet'])\n",
    "\n",
    "\n",
    "\n",
    "except Error as e:\n",
    "print(e)\n",
    "\n",
    "cursor.close()\n",
    "con.close()\n",
    "\n",
    "return df\n",
    "\n",
    "\n",
    "\n",
    "def clean_tweets(self, df):\n",
    "\n",
    "\"\"\"\n",
    "Takes raw tweets and cleans them\n",
    "so we can carry out analysis\n",
    "remove stopwords, punctuation,\n",
    "lower case, html, emoticons.\n",
    "This will be done using Regex\n",
    "? means option so colou?r matches\n",
    "both color and colour.\n",
    "\"\"\"\n",
    "\n",
    "# Do some text preprocessing\n",
    "stopword_list = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "df[\"clean_tweets\"] = None\n",
    "df['len'] = None\n",
    "for i in range(0,len(df['tweet'])):\n",
    "# get rid of anythin that isnt a letter\n",
    "\n",
    "exclusion_list = ['[^a-zA-Z]','rt', 'http', 'co', 'RT']\n",
    "exclusions = '|'.join(exclusion_list)\n",
    "text = re.sub(exclusions, ' ' , df['tweet'][i])\n",
    "text = text.lower()\n",
    "words = text.split()\n",
    "words = [word for word in words if not word in stopword_list]\n",
    " # only use stem of word\n",
    "#words = [ps.stem(word) for word in words]\n",
    "df['clean_tweets'][i] = ' '.join(words)\n",
    "\n",
    "\n",
    "# Create column with data length\n",
    "df['len'] = np.array([len(tweet) for tweet in data[\"clean_tweets\"]])\n",
    "\n",
    "\n",
    "\n",
    "return df\n",
    "\n",
    "\n",
    "\n",
    "def sentiment(self, tweet):\n",
    "\"\"\"\n",
    "This function calculates sentiment\n",
    "on our cleaned tweets.\n",
    "Uses textblob to calculate polarity.\n",
    "Parameters:\n",
    "----------------\n",
    "arg1: takes in a tweet (row of dataframe)\n",
    "\"\"\"\n",
    "\n",
    "# need to improce\n",
    "analysis = TextBlob(tweet)\n",
    "if analysis.sentiment.polarity > 0:\n",
    "return 1\n",
    "elif analysis.sentiment.polarity == 0:\n",
    "return 0\n",
    "else:\n",
    "return -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_to_csv(self, df):\n",
    "\"\"\"\n",
    "Save cleaned data to a csv for further\n",
    "analysis.\n",
    "Parameters:\n",
    "--------------\n",
    "arg1: Pandas dataframe\n",
    "\"\"\"\n",
    "try:\n",
    "df.to_csv(\"clean_tweets.csv\")\n",
    "print(\"\\n\")\n",
    "print(\"csv successfully saved. \\n\")\n",
    "\n",
    "\n",
    "except Error as e:\n",
    "print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def word_cloud(self, df):\n",
    "plt.subplots(figsize = (12,10))\n",
    "wordcloud = WordCloud(\n",
    "background_color = 'white',\n",
    "width = 1000,\n",
    "height = 800).generate(\" \".join(df['clean_tweets']))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "t = TweetObject( host = 'localhost', database = 'twitterdb', user = 'root')\n",
    "\n",
    "data  = t.MySQLConnect(\"SELECT created_at, tweet FROM `TwitterDB`.`Golf`;\")\n",
    "data = t.clean_tweets(data)\n",
    "data['Sentiment'] = np.array([t.sentiment(x) for x in data['clean_tweets']])\n",
    "t.word_cloud(data)\n",
    "t.save_to_csv(data)\n",
    "\n",
    "pos_tweets = [tweet for index, tweet in enumerate(data[\"clean_tweets\"]) if data[\"Sentiment\"][index] > 0]\n",
    "neg_tweets = [tweet for index, tweet in enumerate(data[\"clean_tweets\"]) if data[\"Sentiment\"][index] < 0]\n",
    "neu_tweets = [tweet for index, tweet in enumerate(data[\"clean_tweets\"]) if data[\"Sentiment\"][index] == 0]\n",
    "#Print results\n",
    "print(\"percentage of positive tweets: {}%\".format(100*(len(pos_tweets)/len(data['clean_tweets']))))\n",
    "print(\"percentage of negative tweets: {}%\".format(100*(len(neg_tweets)/len(data['clean_tweets']))))\n",
    "print(\"percentage of neutral tweets: {}%\".format(100*(len(neu_tweets)/len(data['clean_tweets']))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
